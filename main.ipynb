{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e41c8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:18.343203Z",
     "iopub.status.busy": "2025-03-04T00:40:18.342883Z",
     "iopub.status.idle": "2025-03-04T00:40:21.420702Z",
     "shell.execute_reply": "2025-03-04T00:40:21.419650Z",
     "shell.execute_reply.started": "2025-03-04T00:40:18.343178Z"
    },
    "papermill": {
     "duration": 1.039346,
     "end_time": "2025-02-24T22:49:58.644766",
     "exception": false,
     "start_time": "2025-02-24T22:49:57.605420",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49417b48",
   "metadata": {
    "papermill": {
     "duration": 0.003623,
     "end_time": "2025-02-24T22:49:58.653000",
     "exception": false,
     "start_time": "2025-02-24T22:49:58.649377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de27264d",
   "metadata": {
    "papermill": {
     "duration": 0.003513,
     "end_time": "2025-02-24T22:49:58.660327",
     "exception": false,
     "start_time": "2025-02-24T22:49:58.656814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Simple starter code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9507606e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:21.422506Z",
     "iopub.status.busy": "2025-03-04T00:40:21.421968Z",
     "iopub.status.idle": "2025-03-04T00:40:21.582643Z",
     "shell.execute_reply": "2025-03-04T00:40:21.581544Z",
     "shell.execute_reply.started": "2025-03-04T00:40:21.422464Z"
    },
    "papermill": {
     "duration": 0.170795,
     "end_time": "2025-02-24T22:49:58.834832",
     "exception": false,
     "start_time": "2025-02-24T22:49:58.664037",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "w_seed = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/WNCAATourneySeeds.csv\"\n",
    ")\n",
    "m_seed = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/MNCAATourneySeeds.csv\"\n",
    ")\n",
    "seed_df = pd.concat([m_seed, w_seed], axis=0).fillna(0.05)\n",
    "submission_df = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/SampleSubmissionStage2.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780bb316",
   "metadata": {
    "papermill": {
     "duration": 0.003659,
     "end_time": "2025-02-24T22:49:58.843067",
     "exception": false,
     "start_time": "2025-02-24T22:49:58.839408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Team rankings are present in the files WNCAATourneySeeds.csv and MNCAATourneySeeds.csv.\n",
    "\n",
    "- The \"Season\" column indicates the year\n",
    "- The \"Seed\" column indicates the ranking for a given conference (W01 = ranking 1 in conference W)\n",
    "- The \"TeamID\" column contains a unique identifier for every team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40edf9da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:21.585336Z",
     "iopub.status.busy": "2025-03-04T00:40:21.585039Z",
     "iopub.status.idle": "2025-03-04T00:40:21.611893Z",
     "shell.execute_reply": "2025-03-04T00:40:21.610762Z",
     "shell.execute_reply.started": "2025-03-04T00:40:21.585308Z"
    },
    "papermill": {
     "duration": 0.031431,
     "end_time": "2025-02-24T22:49:58.878444",
     "exception": false,
     "start_time": "2025-02-24T22:49:58.847013",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "seed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c12c94a",
   "metadata": {
    "papermill": {
     "duration": 0.003721,
     "end_time": "2025-02-24T22:49:58.887081",
     "exception": false,
     "start_time": "2025-02-24T22:49:58.883360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The sample_submission.csv file contains an \"ID\" column with the format year_teamID1_teamID2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a285cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:21.613882Z",
     "iopub.status.busy": "2025-03-04T00:40:21.613579Z",
     "iopub.status.idle": "2025-03-04T00:40:21.626164Z",
     "shell.execute_reply": "2025-03-04T00:40:21.625180Z",
     "shell.execute_reply.started": "2025-03-04T00:40:21.613844Z"
    },
    "papermill": {
     "duration": 0.015085,
     "end_time": "2025-02-24T22:49:58.906107",
     "exception": false,
     "start_time": "2025-02-24T22:49:58.891022",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d983ac83",
   "metadata": {
    "papermill": {
     "duration": 0.004022,
     "end_time": "2025-02-24T22:49:58.914921",
     "exception": false,
     "start_time": "2025-02-24T22:49:58.910899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Extract game info and team rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8009319b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:21.627691Z",
     "iopub.status.busy": "2025-03-04T00:40:21.627331Z",
     "iopub.status.idle": "2025-03-04T00:40:22.084633Z",
     "shell.execute_reply": "2025-03-04T00:40:22.083297Z",
     "shell.execute_reply.started": "2025-03-04T00:40:21.627663Z"
    },
    "papermill": {
     "duration": 0.291754,
     "end_time": "2025-02-24T22:49:59.210864",
     "exception": false,
     "start_time": "2025-02-24T22:49:58.919110",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_game_info(id_str):\n",
    "    # Extract year and team_ids\n",
    "    parts = id_str.split(\"_\")\n",
    "    year = int(parts[0])\n",
    "    teamID1 = int(parts[1])\n",
    "    teamID2 = int(parts[2])\n",
    "    return year, teamID1, teamID2\n",
    "\n",
    "\n",
    "def extract_seed_value(seed_str):\n",
    "    # Extract seed value\n",
    "    try:\n",
    "        return int(seed_str[1:])\n",
    "    # Set seed to 16 for unselected teams and errors\n",
    "    except ValueError:\n",
    "        return 16\n",
    "\n",
    "\n",
    "# Reformat the data\n",
    "submission_df[[\"Season\", \"TeamID1\", \"TeamID2\"]] = (\n",
    "    submission_df[\"ID\"].apply(extract_game_info).tolist()\n",
    ")\n",
    "seed_df[\"SeedValue\"] = seed_df[\"Seed\"].apply(extract_seed_value)\n",
    "\n",
    "# Merge seed information for TeamID1\n",
    "submission_df = pd.merge(\n",
    "    submission_df,\n",
    "    seed_df[[\"Season\", \"TeamID\", \"SeedValue\"]],\n",
    "    left_on=[\"Season\", \"TeamID1\"],\n",
    "    right_on=[\"Season\", \"TeamID\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "submission_df = submission_df.rename(columns={\"SeedValue\": \"SeedValue1\"}).drop(\n",
    "    columns=[\"TeamID\"]\n",
    ")\n",
    "\n",
    "# Merge seed information for TeamID2\n",
    "submission_df = pd.merge(\n",
    "    submission_df,\n",
    "    seed_df[[\"Season\", \"TeamID\", \"SeedValue\"]],\n",
    "    left_on=[\"Season\", \"TeamID2\"],\n",
    "    right_on=[\"Season\", \"TeamID\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "submission_df = submission_df.rename(columns={\"SeedValue\": \"SeedValue2\"}).drop(\n",
    "    columns=[\"TeamID\"]\n",
    ")\n",
    "print(submission_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba83ab58",
   "metadata": {
    "papermill": {
     "duration": 0.003876,
     "end_time": "2025-02-24T22:49:59.219384",
     "exception": false,
     "start_time": "2025-02-24T22:49:59.215508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Make your predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e87117-4a7f-43b9-beb7-53e022df1bef",
   "metadata": {},
   "source": [
    "### With Massey Ordinals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33ad47b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:22.086264Z",
     "iopub.status.busy": "2025-03-04T00:40:22.085883Z",
     "iopub.status.idle": "2025-03-04T00:40:25.476073Z",
     "shell.execute_reply": "2025-03-04T00:40:25.474958Z",
     "shell.execute_reply.started": "2025-03-04T00:40:22.086227Z"
    },
    "papermill": {
     "duration": 2.296789,
     "end_time": "2025-02-24T22:50:01.520283",
     "exception": false,
     "start_time": "2025-02-24T22:49:59.223494",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Overall ranking of the team in the underlying system.\n",
    "m_massey_ordinals_df = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/MMasseyOrdinals.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155cf324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:25.477412Z",
     "iopub.status.busy": "2025-03-04T00:40:25.477099Z",
     "iopub.status.idle": "2025-03-04T00:40:25.487760Z",
     "shell.execute_reply": "2025-03-04T00:40:25.486753Z",
     "shell.execute_reply.started": "2025-03-04T00:40:25.477356Z"
    },
    "papermill": {
     "duration": 0.013324,
     "end_time": "2025-02-24T22:50:01.538480",
     "exception": false,
     "start_time": "2025-02-24T22:50:01.525156",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "m_massey_ordinals_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d008dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:25.489552Z",
     "iopub.status.busy": "2025-03-04T00:40:25.489198Z",
     "iopub.status.idle": "2025-03-04T00:40:25.525634Z",
     "shell.execute_reply": "2025-03-04T00:40:25.524589Z",
     "shell.execute_reply.started": "2025-03-04T00:40:25.489520Z"
    },
    "papermill": {
     "duration": 0.018724,
     "end_time": "2025-02-24T22:50:01.562130",
     "exception": false,
     "start_time": "2025-02-24T22:50:01.543406",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "m_massey_ordinals_2025_df = m_massey_ordinals_df[m_massey_ordinals_df[\"Season\"] == 2025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab271a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:25.529821Z",
     "iopub.status.busy": "2025-03-04T00:40:25.529543Z",
     "iopub.status.idle": "2025-03-04T00:40:25.539138Z",
     "shell.execute_reply": "2025-03-04T00:40:25.538100Z",
     "shell.execute_reply.started": "2025-03-04T00:40:25.529791Z"
    },
    "papermill": {
     "duration": 0.015268,
     "end_time": "2025-02-24T22:50:01.582467",
     "exception": false,
     "start_time": "2025-02-24T22:50:01.567199",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "m_massey_ordinals_2025_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877241d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:25.541245Z",
     "iopub.status.busy": "2025-03-04T00:40:25.540968Z",
     "iopub.status.idle": "2025-03-04T00:40:25.570189Z",
     "shell.execute_reply": "2025-03-04T00:40:25.569122Z",
     "shell.execute_reply.started": "2025-03-04T00:40:25.541220Z"
    },
    "papermill": {
     "duration": 0.018354,
     "end_time": "2025-02-24T22:50:01.606095",
     "exception": false,
     "start_time": "2025-02-24T22:50:01.587741",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "m_mo_ave_df = pd.DataFrame(\n",
    "    m_massey_ordinals_2025_df.groupby(\"TeamID\")[\"OrdinalRank\"].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb172c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:25.571788Z",
     "iopub.status.busy": "2025-03-04T00:40:25.571361Z",
     "iopub.status.idle": "2025-03-04T00:40:25.580502Z",
     "shell.execute_reply": "2025-03-04T00:40:25.579508Z",
     "shell.execute_reply.started": "2025-03-04T00:40:25.571753Z"
    },
    "papermill": {
     "duration": 0.014473,
     "end_time": "2025-02-24T22:50:01.625637",
     "exception": false,
     "start_time": "2025-02-24T22:50:01.611164",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "m_mo_ave_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c179dd1",
   "metadata": {
    "papermill": {
     "duration": 0.004066,
     "end_time": "2025-02-24T22:50:01.634784",
     "exception": false,
     "start_time": "2025-02-24T22:50:01.630718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Method 1: Bradley Terry Model\n",
    "\n",
    "Predicts the winning percentage based on the difference in team standings using a logistic function\n",
    "* Statistically well-founded model\n",
    "* Need to adjust parameter c (to fit the data set)\n",
    "* Often used in sports forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a405474e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:25.582142Z",
     "iopub.status.busy": "2025-03-04T00:40:25.581741Z",
     "iopub.status.idle": "2025-03-04T00:40:25.600956Z",
     "shell.execute_reply": "2025-03-04T00:40:25.599499Z",
     "shell.execute_reply.started": "2025-03-04T00:40:25.582099Z"
    },
    "papermill": {
     "duration": 0.433273,
     "end_time": "2025-02-24T22:50:02.072385",
     "exception": false,
     "start_time": "2025-02-24T22:50:01.639112",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "\n",
    "def bradley_terry_probability(\n",
    "    team_a: int, team_b: int, ranks: pd.DataFrame, c=0.01\n",
    ") -> np.float64:\n",
    "    rank_diff = ranks.loc[team_b] - ranks.loc[team_a]\n",
    "    prob = expit(c * rank_diff)  # Convert to probability with logistic function\n",
    "\n",
    "    return prob[\"OrdinalRank\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07fc99e",
   "metadata": {
    "papermill": {
     "duration": 0.004467,
     "end_time": "2025-02-24T22:50:02.082141",
     "exception": false,
     "start_time": "2025-02-24T22:50:02.077674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Method2: ELO Rating\n",
    "\n",
    "Applying the ELO rating system, we predict the winning percentage based on the difference in rankings\n",
    "* Proven in many competitions, including chess\n",
    "* Scale parameters need to be adjusted\n",
    "* Can be adjusted more accurately with past competition results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d373e823",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:25.603198Z",
     "iopub.status.busy": "2025-03-04T00:40:25.602313Z",
     "iopub.status.idle": "2025-03-04T00:40:25.625558Z",
     "shell.execute_reply": "2025-03-04T00:40:25.624477Z",
     "shell.execute_reply.started": "2025-03-04T00:40:25.603156Z"
    },
    "papermill": {
     "duration": 0.011693,
     "end_time": "2025-02-24T22:50:02.098637",
     "exception": false,
     "start_time": "2025-02-24T22:50:02.086944",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def elo_win_probability(team_a: int, team_b: int, ranks: pd.DataFrame, scale=400):\n",
    "    max_rank = ranks.max()\n",
    "    # Reverse OrdinalRank and treat it like an ELO rating (smaller is stronger)\n",
    "    elo_like_ratings = max_rank - ranks\n",
    "\n",
    "    rating_diff = elo_like_ratings.loc[team_a] - elo_like_ratings.loc[team_b]\n",
    "    prob = 1.0 / (1.0 + 10 ** (-rating_diff / scale))\n",
    "\n",
    "    return prob[\"OrdinalRank\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd41c66",
   "metadata": {
    "papermill": {
     "duration": 0.004289,
     "end_time": "2025-02-24T22:50:02.107954",
     "exception": false,
     "start_time": "2025-02-24T22:50:02.103665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Method 3: Normalized Rank\n",
    "\n",
    "A method that normalizes a team's ranking to the range [0,1] and interprets it directly as a probability\n",
    "* Simple and easy to implement\n",
    "* Intuitive reflection of relative strength among teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3fe74a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:25.627381Z",
     "iopub.status.busy": "2025-03-04T00:40:25.626689Z",
     "iopub.status.idle": "2025-03-04T00:40:25.645535Z",
     "shell.execute_reply": "2025-03-04T00:40:25.644511Z",
     "shell.execute_reply.started": "2025-03-04T00:40:25.627339Z"
    },
    "papermill": {
     "duration": 0.010918,
     "end_time": "2025-02-24T22:50:02.123531",
     "exception": false,
     "start_time": "2025-02-24T22:50:02.112613",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def normalized_rank_probability(team_a, team_b, ranks):\n",
    "    # Normalized by inverting the ranks (because smaller is stronger)\n",
    "    reversed_ranks = ranks.max() - ranks\n",
    "    normalized = (reversed_ranks - reversed_ranks.min()) / (\n",
    "        reversed_ranks.max() - reversed_ranks.min()\n",
    "    )\n",
    "\n",
    "    # Calculate win rate from ratio of normalized values\n",
    "    p_a = normalized.loc[team_a]\n",
    "    p_b = normalized.loc[team_b]\n",
    "    win_prob = p_a / (p_a + p_b)\n",
    "\n",
    "    return win_prob[\"OrdinalRank\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d89a61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:25.646907Z",
     "iopub.status.busy": "2025-03-04T00:40:25.646574Z",
     "iopub.status.idle": "2025-03-04T00:40:25.663103Z",
     "shell.execute_reply": "2025-03-04T00:40:25.661955Z",
     "shell.execute_reply.started": "2025-03-04T00:40:25.646877Z"
    },
    "papermill": {
     "duration": 1049.795222,
     "end_time": "2025-02-24T23:07:31.923919",
     "exception": false,
     "start_time": "2025-02-24T22:50:02.128697",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# for target_team in m_mo_ave_df.index:\n",
    "#     for opposing_team in m_mo_ave_df.index:\n",
    "#         match_id = f\"2025_{target_team}_{opposing_team}\"\n",
    "#         pred = bradley_terry_probability(target_team, opposing_team, m_mo_ave_df)\n",
    "#         # pred = elo_win_probability(target_team, opposing_team, m_mo_ave_df)\n",
    "#         # pred = normalized_rank_probability(target_team, opposing_team, m_mo_ave_df)\n",
    "\n",
    "#         submission_df.loc[submission_df[\"ID\"] == match_id, \"Pred\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06863be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:25.664550Z",
     "iopub.status.busy": "2025-03-04T00:40:25.664173Z",
     "iopub.status.idle": "2025-03-04T00:40:25.681199Z",
     "shell.execute_reply": "2025-03-04T00:40:25.680244Z",
     "shell.execute_reply.started": "2025-03-04T00:40:25.664525Z"
    },
    "papermill": {
     "duration": 0.019743,
     "end_time": "2025-02-24T23:07:31.949502",
     "exception": false,
     "start_time": "2025-02-24T23:07:31.929759",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9354c8d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:25.682351Z",
     "iopub.status.busy": "2025-03-04T00:40:25.682097Z",
     "iopub.status.idle": "2025-03-04T00:40:25.699370Z",
     "shell.execute_reply": "2025-03-04T00:40:25.698493Z",
     "shell.execute_reply.started": "2025-03-04T00:40:25.682330Z"
    },
    "papermill": {
     "duration": 0.031388,
     "end_time": "2025-02-24T23:07:31.987247",
     "exception": false,
     "start_time": "2025-02-24T23:07:31.955859",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# stats = submission_df.iloc[:, 1].describe()\n",
    "# print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda2e2c4-0eba-4a28-806f-bec45b1fd430",
   "metadata": {},
   "source": [
    "### With XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf7447-2000-4d06-8cb2-651f3bea67e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:25.700761Z",
     "iopub.status.busy": "2025-03-04T00:40:25.700439Z",
     "iopub.status.idle": "2025-03-04T00:40:26.456815Z",
     "shell.execute_reply": "2025-03-04T00:40:26.456009Z",
     "shell.execute_reply.started": "2025-03-04T00:40:25.700730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Read Data\n",
    "\n",
    "men_tournament = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/MNCAATourneyDetailedResults.csv\"\n",
    ")\n",
    "men_seeds = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/MNCAATourneySeeds.csv\"\n",
    ")\n",
    "men_regular = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/MRegularSeasonDetailedResults.csv\"\n",
    ")\n",
    "\n",
    "women_tournament = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/WNCAATourneyDetailedResults.csv\"\n",
    ")\n",
    "women_seeds = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/WNCAATourneySeeds.csv\"\n",
    ")\n",
    "women_regular = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/WRegularSeasonDetailedResults.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ee9cd2-729a-4854-b066-3c961047b84a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:26.457832Z",
     "iopub.status.busy": "2025-03-04T00:40:26.457579Z",
     "iopub.status.idle": "2025-03-04T00:40:26.473496Z",
     "shell.execute_reply": "2025-03-04T00:40:26.472449Z",
     "shell.execute_reply.started": "2025-03-04T00:40:26.457810Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "men_tournament.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7ecc2b-14ac-4c7f-94a3-743661130871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:26.474854Z",
     "iopub.status.busy": "2025-03-04T00:40:26.474542Z",
     "iopub.status.idle": "2025-03-04T00:40:26.493096Z",
     "shell.execute_reply": "2025-03-04T00:40:26.492003Z",
     "shell.execute_reply.started": "2025-03-04T00:40:26.474829Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "men_seeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c425243-c149-4c92-b9ef-85aa4fb178b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:26.494573Z",
     "iopub.status.busy": "2025-03-04T00:40:26.494192Z",
     "iopub.status.idle": "2025-03-04T00:40:26.522870Z",
     "shell.execute_reply": "2025-03-04T00:40:26.521823Z",
     "shell.execute_reply.started": "2025-03-04T00:40:26.494538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "men_regular.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4549ccf6-2156-44eb-acae-7c6c0633c0ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:26.524829Z",
     "iopub.status.busy": "2025-03-04T00:40:26.524470Z",
     "iopub.status.idle": "2025-03-04T00:40:26.571033Z",
     "shell.execute_reply": "2025-03-04T00:40:26.569948Z",
     "shell.execute_reply.started": "2025-03-04T00:40:26.524793Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_train_and_test_data(\n",
    "    men_tournament, men_seeds, men_regular, women_tournament, women_seeds, women_regular\n",
    "):\n",
    "    men_tournament.drop([\"NumOT\", \"WLoc\"], axis=1, inplace=True)\n",
    "    women_tournament.drop([\"NumOT\", \"WLoc\"], axis=1, inplace=True)\n",
    "\n",
    "    # \"Set\" denotes whether the data is from the regular season or tournament (1 = tournament, 0 = regular season)\n",
    "    men_tournament[\"set\"] = 1\n",
    "    men_regular[\"set\"] = 0\n",
    "    women_tournament[\"set\"] = 1\n",
    "    women_regular[\"set\"] = 0\n",
    "\n",
    "    men_seeds[\"Seed\"] = men_seeds[\"Seed\"].apply(lambda x: int(x[1:3]))\n",
    "    women_seeds[\"Seed\"] = women_seeds[\"Seed\"].apply(lambda x: int(x[1:3]))\n",
    "\n",
    "    # Combine regular season data and tournament data into one dataframe\n",
    "    # Add feature for gender to try to quantify some differences in efficiency, playstyle, etc... (1 = men, 0 = women)\n",
    "    men_box = pd.concat([men_tournament, men_regular], ignore_index=True)\n",
    "    women_box = pd.concat([women_tournament, women_regular], ignore_index=True)\n",
    "\n",
    "    men_box[\"gender\"] = 1\n",
    "    women_box[\"gender\"] = 0\n",
    "\n",
    "    men_women_box = pd.concat([men_box, women_box], ignore_index=True)\n",
    "    men_women_seeds = pd.concat([men_seeds, women_seeds], ignore_index=True)\n",
    "\n",
    "    # Rename the features for the winning team as \"TeamA\" and \"TeamB\" for the losing team... also flip the labels to create double the data\n",
    "    # (each game can be seen from two perspectives... the winner and the loser)\n",
    "    w_df = men_women_box.loc[\n",
    "        :,\n",
    "        [\n",
    "            \"Season\",\n",
    "            \"DayNum\",\n",
    "            \"WTeamID\",\n",
    "            \"WScore\",\n",
    "            \"LTeamID\",\n",
    "            \"LScore\",\n",
    "            \"WFGM\",\n",
    "            \"WFGA\",\n",
    "            \"WFGM3\",\n",
    "            \"WFGA3\",\n",
    "            \"WFTM\",\n",
    "            \"WFTA\",\n",
    "            \"WOR\",\n",
    "            \"WDR\",\n",
    "            \"WAst\",\n",
    "            \"WTO\",\n",
    "            \"WStl\",\n",
    "            \"WBlk\",\n",
    "            \"WPF\",\n",
    "            \"LFGM\",\n",
    "            \"LFGA\",\n",
    "            \"LFGM3\",\n",
    "            \"LFGA3\",\n",
    "            \"LFTM\",\n",
    "            \"LFTA\",\n",
    "            \"LOR\",\n",
    "            \"LDR\",\n",
    "            \"LAst\",\n",
    "            \"LTO\",\n",
    "            \"LStl\",\n",
    "            \"LBlk\",\n",
    "            \"LPF\",\n",
    "            \"set\",\n",
    "            \"gender\",\n",
    "        ],\n",
    "    ]  # Exclude ['NumOT', 'WLoc'] from men_women_box\n",
    "\n",
    "    w_df.columns = [\n",
    "        \"Season\",\n",
    "        \"DayNum\",\n",
    "        \"ATeamID\",\n",
    "        \"AScore\",\n",
    "        \"BTeamID\",\n",
    "        \"BScore\",\n",
    "        \"AFGM\",\n",
    "        \"AFGA\",\n",
    "        \"AFGM3\",\n",
    "        \"AFGA3\",\n",
    "        \"AFTM\",\n",
    "        \"AFTA\",\n",
    "        \"AOR\",\n",
    "        \"ADR\",\n",
    "        \"AAst\",\n",
    "        \"ATO\",\n",
    "        \"AStl\",\n",
    "        \"ABlk\",\n",
    "        \"APF\",\n",
    "        \"BFGM\",\n",
    "        \"BFGA\",\n",
    "        \"BFGM3\",\n",
    "        \"BFGA3\",\n",
    "        \"BFTM\",\n",
    "        \"BFTA\",\n",
    "        \"BOR\",\n",
    "        \"BDR\",\n",
    "        \"BAst\",\n",
    "        \"BTO\",\n",
    "        \"BStl\",\n",
    "        \"BBlk\",\n",
    "        \"BPF\",\n",
    "        \"Set\",\n",
    "        \"Gender\",\n",
    "    ]  # W -> A, L -> B\n",
    "\n",
    "    l_df = men_women_box.loc[\n",
    "        :,\n",
    "        [\n",
    "            \"Season\",\n",
    "            \"DayNum\",\n",
    "            \"LTeamID\",\n",
    "            \"LScore\",\n",
    "            \"WTeamID\",\n",
    "            \"WScore\",\n",
    "            \"LFGM\",\n",
    "            \"LFGA\",\n",
    "            \"LFGM3\",\n",
    "            \"LFGA3\",\n",
    "            \"LFTM\",\n",
    "            \"LFTA\",\n",
    "            \"LOR\",\n",
    "            \"LDR\",\n",
    "            \"LAst\",\n",
    "            \"LTO\",\n",
    "            \"LStl\",\n",
    "            \"LBlk\",\n",
    "            \"LPF\",\n",
    "            \"WFGM\",\n",
    "            \"WFGA\",\n",
    "            \"WFGM3\",\n",
    "            \"WFGA3\",\n",
    "            \"WFTM\",\n",
    "            \"WFTA\",\n",
    "            \"WOR\",\n",
    "            \"WDR\",\n",
    "            \"WAst\",\n",
    "            \"WTO\",\n",
    "            \"WStl\",\n",
    "            \"WBlk\",\n",
    "            \"WPF\",\n",
    "            \"set\",\n",
    "            \"gender\",\n",
    "        ],\n",
    "    ]\n",
    "\n",
    "    l_df.columns = [\n",
    "        \"Season\",\n",
    "        \"DayNum\",\n",
    "        \"ATeamID\",\n",
    "        \"AScore\",\n",
    "        \"BTeamID\",\n",
    "        \"BScore\",\n",
    "        \"AFGM\",\n",
    "        \"AFGA\",\n",
    "        \"AFGM3\",\n",
    "        \"AFGA3\",\n",
    "        \"AFTM\",\n",
    "        \"AFTA\",\n",
    "        \"AOR\",\n",
    "        \"ADR\",\n",
    "        \"AAst\",\n",
    "        \"ATO\",\n",
    "        \"AStl\",\n",
    "        \"ABlk\",\n",
    "        \"APF\",\n",
    "        \"BFGM\",\n",
    "        \"BFGA\",\n",
    "        \"BFGM3\",\n",
    "        \"BFGA3\",\n",
    "        \"BFTM\",\n",
    "        \"BFTA\",\n",
    "        \"BOR\",\n",
    "        \"BDR\",\n",
    "        \"BAst\",\n",
    "        \"BTO\",\n",
    "        \"BStl\",\n",
    "        \"BBlk\",\n",
    "        \"BPF\",\n",
    "        \"Set\",\n",
    "        \"Gender\",\n",
    "    ]\n",
    "\n",
    "    # Concat new dataframes/columns\n",
    "    # Create a column to denote the outcome of a game for both TeamA and TeamB\n",
    "    all_box = pd.concat([w_df, l_df], axis=0)\n",
    "    all_box[\"AWin\"] = (all_box[\"AScore\"] > all_box[\"BScore\"]).astype(int)\n",
    "    all_box[\"ALoss\"] = (all_box[\"AScore\"] < all_box[\"BScore\"]).astype(int)\n",
    "    all_box[\"BWin\"] = (all_box[\"AScore\"] < all_box[\"BScore\"]).astype(int)\n",
    "    all_box[\"BLoss\"] = (all_box[\"AScore\"] > all_box[\"BScore\"]).astype(int)\n",
    "\n",
    "    # The start of creating features for both TeamA and TeamB\n",
    "    # Group by Season and the teamID to calculate the total for a specified column\n",
    "    # A Features\n",
    "    all_box[\"AWins\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"AWin\"].transform(\"sum\")\n",
    "    all_box[\"ALosses\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"ALoss\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"AGames\"] = all_box[\"AWins\"] + all_box[\"ALosses\"]\n",
    "    all_box[\"ATotalPts\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"AScore\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"ATotalFGM\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"AFGM\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"ATotalFGA\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"AFGA\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"ATotal3PM\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"AFGM3\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"ATotal3PA\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"AFGA3\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"ATotalFTM\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"AFTM\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"ATotalFTA\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"AFTA\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"ATotalOR\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"AOR\"].transform(\"sum\")\n",
    "    all_box[\"ATotalDR\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"ADR\"].transform(\"sum\")\n",
    "    all_box[\"ATotalAst\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"AAst\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"ATotalTO\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"ATO\"].transform(\"sum\")\n",
    "    all_box[\"ATotalStl\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"AStl\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"ATotalBlk\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"ABlk\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"ATotalPf\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"APF\"].transform(\"sum\")\n",
    "    # B Features\n",
    "    all_box[\"BWins\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BWin\"].transform(\"sum\")\n",
    "    all_box[\"BLosses\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BLoss\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"BGames\"] = all_box[\"BWins\"] + all_box[\"BLosses\"]\n",
    "    all_box[\"BTotalPts\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BScore\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"BTotalFGM\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BFGM\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"BTotalFGA\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BFGA\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"BTotal3PM\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BFGM3\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"BTotal3PA\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BFGA3\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"BTotalFTM\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BFTM\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"BTotalFTA\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BFTA\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"BTotalOR\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BOR\"].transform(\"sum\")\n",
    "    all_box[\"BTotalDR\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BDR\"].transform(\"sum\")\n",
    "    all_box[\"BTotalAst\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BAst\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"BTotalTO\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BTO\"].transform(\"sum\")\n",
    "    all_box[\"BTotalStl\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BStl\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"BTotalBlk\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BBlk\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"BTotalPf\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BPF\"].transform(\"sum\")\n",
    "\n",
    "    # More total features\n",
    "    # Group by Season and the teamID to calculate the total for a specified column\n",
    "    # These columns are for the opponent of a specified team... can be used to identify how well a team did against an opponent relative to their average performance\n",
    "\n",
    "    all_box[\"AOppWins\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BWin\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"AOppLosses\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"BLoss\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"BOppWins\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"AWin\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"BOppLosses\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"ALoss\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"AOppGames\"] = all_box[\"BOppWins\"] + all_box[\"BOppLosses\"]\n",
    "    all_box[\"BOppGames\"] = all_box[\"BOppWins\"] + all_box[\"BOppLosses\"]\n",
    "\n",
    "    # A Opponent features\n",
    "    all_box[\"AOppPts\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"BScore\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"AOppFGM\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"BFGM\"].transform(\"sum\")\n",
    "    all_box[\"AOppFGA\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"BFGA\"].transform(\"sum\")\n",
    "    all_box[\"AOpp3PM\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"BFGM3\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"AOpp3PA\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"BFGA3\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"AOppFTM\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"BFTM\"].transform(\"sum\")\n",
    "    all_box[\"AOppFTA\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"BFTA\"].transform(\"sum\")\n",
    "    all_box[\"AOppOR\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"BOR\"].transform(\"sum\")\n",
    "    all_box[\"AOppDR\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"BDR\"].transform(\"sum\")\n",
    "    all_box[\"AOppAst\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"BAst\"].transform(\"sum\")\n",
    "    all_box[\"AOppTO\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"BTO\"].transform(\"sum\")\n",
    "    all_box[\"AOppStl\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"BStl\"].transform(\"sum\")\n",
    "    all_box[\"AOppBlk\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"BBlk\"].transform(\"sum\")\n",
    "    all_box[\"AOppPf\"] = all_box.groupby([\"Season\", \"ATeamID\"])[\"BPF\"].transform(\"sum\")\n",
    "\n",
    "    # B Opponent features\n",
    "    all_box[\"BOppPts\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"AScore\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"BOppFGM\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"AFGM\"].transform(\"sum\")\n",
    "    all_box[\"BOppFGA\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"AFGA\"].transform(\"sum\")\n",
    "    all_box[\"BOpp3PM\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"AFGM3\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"BOpp3PA\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"AFGA3\"].transform(\n",
    "        \"sum\"\n",
    "    )\n",
    "    all_box[\"BOppFTM\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"AFTM\"].transform(\"sum\")\n",
    "    all_box[\"BOppFTA\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"AFTA\"].transform(\"sum\")\n",
    "    all_box[\"BOppOR\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"AOR\"].transform(\"sum\")\n",
    "    all_box[\"BOppDR\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"ADR\"].transform(\"sum\")\n",
    "    all_box[\"BOppAst\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"AAst\"].transform(\"sum\")\n",
    "    all_box[\"BOppTO\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"ATO\"].transform(\"sum\")\n",
    "    all_box[\"BOppStl\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"AStl\"].transform(\"sum\")\n",
    "    all_box[\"BOppBlk\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"ABlk\"].transform(\"sum\")\n",
    "    all_box[\"BOppPf\"] = all_box.groupby([\"Season\", \"BTeamID\"])[\"APF\"].transform(\"sum\")\n",
    "\n",
    "    # Formula to give a rough estimate for the number of possessions a team has...\n",
    "    all_box[\"ATotalPoss\"] = (\n",
    "        all_box[\"ATotalFGA\"]\n",
    "        + 0.44 * all_box[\"ATotalFTA\"]\n",
    "        - all_box[\"ATotalOR\"]\n",
    "        + all_box[\"ATotalTO\"]\n",
    "    )\n",
    "    all_box[\"BTotalPoss\"] = (\n",
    "        all_box[\"BTotalFGA\"]\n",
    "        + 0.44 * all_box[\"BTotalFTA\"]\n",
    "        - all_box[\"BTotalOR\"]\n",
    "        + all_box[\"BTotalTO\"]\n",
    "    )\n",
    "    all_box[\"AOppPoss\"] = (\n",
    "        all_box[\"AOppFGA\"]\n",
    "        + 0.44 * all_box[\"AOppFTA\"]\n",
    "        - all_box[\"AOppOR\"]\n",
    "        + all_box[\"AOppTO\"]\n",
    "    )\n",
    "    all_box[\"BOppPoss\"] = (\n",
    "        all_box[\"BOppFGA\"]\n",
    "        + 0.44 * all_box[\"BOppFTA\"]\n",
    "        - all_box[\"BOppOR\"]\n",
    "        + all_box[\"BOppTO\"]\n",
    "    )\n",
    "\n",
    "    # Main dataframe to engineer features\n",
    "    # Included some advanced statistics for each team as well as each teams' opponents\n",
    "    df = pd.DataFrame()\n",
    "    df[\"Season\"] = all_box[\"Season\"]\n",
    "    df[\"Gender\"] = all_box[\"Gender\"]\n",
    "\n",
    "    df[\"TeamA\"] = all_box[\"ATeamID\"]\n",
    "    df[\"TeamB\"] = all_box[\"BTeamID\"]\n",
    "\n",
    "    df[\"AWRatio\"] = all_box[\"AWins\"] / all_box[\"AGames\"]\n",
    "    df[\"BWRatio\"] = all_box[\"BWins\"] / all_box[\"BGames\"]\n",
    "\n",
    "    df[\"AEFG\"] = (all_box[\"ATotalFGM\"] + 0.5 * all_box[\"ATotal3PM\"]) / all_box[\n",
    "        \"ATotalFGA\"\n",
    "    ]\n",
    "    df[\"BEFG\"] = (all_box[\"BTotalFGM\"] + 0.5 * all_box[\"BTotal3PM\"]) / all_box[\n",
    "        \"BTotalFGA\"\n",
    "    ]\n",
    "\n",
    "    df[\"AOppEFG\"] = (all_box[\"AOppFGM\"] + 0.5 * all_box[\"AOpp3PM\"]) / all_box[\"AOppFGA\"]\n",
    "    df[\"BOppEFG\"] = (all_box[\"BOppFGM\"] + 0.5 * all_box[\"BOpp3PM\"]) / all_box[\"BOppFGA\"]\n",
    "\n",
    "    df[\"APPP\"] = all_box[\"ATotalPts\"] / all_box[\"ATotalPoss\"]\n",
    "    df[\"BPPP\"] = all_box[\"BTotalPts\"] / all_box[\"BTotalPoss\"]\n",
    "\n",
    "    df[\"AOppPPP\"] = all_box[\"AOppPts\"] / all_box[\"AOppPoss\"]\n",
    "    df[\"BOppPPP\"] = all_box[\"BOppPts\"] / all_box[\"BOppPoss\"]\n",
    "\n",
    "    df[\"ATS\"] = all_box[\"ATotalPts\"] / (\n",
    "        2 * (all_box[\"ATotalFGA\"] + 0.475 * all_box[\"ATotalFTA\"])\n",
    "    )\n",
    "    df[\"BTS\"] = all_box[\"BTotalPts\"] / (\n",
    "        2 * (all_box[\"BTotalFGA\"] + 0.475 * all_box[\"BTotalFTA\"])\n",
    "    )\n",
    "\n",
    "    df[\"AOppTS\"] = all_box[\"AOppPts\"] / (\n",
    "        2 * (all_box[\"AOppFGA\"] + 0.475 * all_box[\"AOppFTA\"])\n",
    "    )\n",
    "    df[\"BOppTS\"] = all_box[\"BOppPts\"] / (\n",
    "        2 * (all_box[\"BOppFGA\"] + 0.475 * all_box[\"BOppFTA\"])\n",
    "    )\n",
    "\n",
    "    df[\"AORTG\"] = 100 * all_box[\"ATotalPts\"] / all_box[\"ATotalPoss\"]\n",
    "    df[\"BORTG\"] = 100 * all_box[\"BTotalPts\"] / all_box[\"BTotalPoss\"]\n",
    "\n",
    "    df[\"ADRTG\"] = 100 * all_box[\"AOppPts\"] / all_box[\"AOppPoss\"]\n",
    "    df[\"BDRTG\"] = 100 * all_box[\"BOppPts\"] / all_box[\"BOppPoss\"]\n",
    "\n",
    "    df[\"ATOVPct\"] = all_box[\"ATotalTO\"] / (\n",
    "        all_box[\"ATotalFGA\"] + 0.475 * all_box[\"ATotalFTA\"] + all_box[\"ATotalTO\"]\n",
    "    )\n",
    "    df[\"BTOVPct\"] = all_box[\"BTotalTO\"] / (\n",
    "        all_box[\"BTotalFGA\"] + 0.475 * all_box[\"BTotalFTA\"] + all_box[\"BTotalTO\"]\n",
    "    )\n",
    "\n",
    "    df[\"AOppTOV\"] = all_box[\"AOppTO\"] / (\n",
    "        all_box[\"AOppFGA\"] + 0.475 * all_box[\"AOppFTA\"] + all_box[\"AOppTO\"]\n",
    "    )\n",
    "    df[\"BOppTOV\"] = all_box[\"BOppTO\"] / (\n",
    "        all_box[\"BOppFGA\"] + 0.475 * all_box[\"BOppFTA\"] + all_box[\"BOppTO\"]\n",
    "    )\n",
    "\n",
    "    df[\"AORPct\"] = all_box[\"ATotalOR\"] / (all_box[\"ATotalOR\"] + all_box[\"AOppDR\"])\n",
    "    df[\"BORPct\"] = all_box[\"BTotalOR\"] / (all_box[\"BTotalOR\"] + all_box[\"BOppDR\"])\n",
    "\n",
    "    df[\"ADRPct\"] = all_box[\"ATotalDR\"] / (all_box[\"ATotalDR\"] + all_box[\"AOppOR\"])\n",
    "    df[\"BDRPct\"] = all_box[\"BTotalDR\"] / (all_box[\"BTotalDR\"] + all_box[\"BOppOR\"])\n",
    "\n",
    "    df[\"AFTR\"] = all_box[\"ATotalFTA\"] / all_box[\"ATotalFGA\"]\n",
    "    df[\"BFTR\"] = all_box[\"BTotalFTA\"] / all_box[\"BTotalFGA\"]\n",
    "\n",
    "    df[\"AOppFTR\"] = all_box[\"AOppFTA\"] / all_box[\"AOppFGA\"]\n",
    "    df[\"BOppFTR\"] = all_box[\"BOppFTA\"] / all_box[\"BOppFGA\"]\n",
    "\n",
    "    df[\"4fODiff\"] = (\n",
    "        (0.4 * (df[\"AEFG\"] - df[\"BEFG\"]))\n",
    "        - (0.25 * (df[\"ATOVPct\"] - df[\"BTOVPct\"]))\n",
    "        + (0.2 * (df[\"AORPct\"] - df[\"BORPct\"]))\n",
    "        + (0.15 * (df[\"AFTR\"] - df[\"BFTR\"]))\n",
    "    )\n",
    "    df[\"4fDDiff\"] = (\n",
    "        -(0.4 * (df[\"AOppEFG\"] - df[\"BOppEFG\"]))\n",
    "        + (0.25 * (df[\"AOppTOV\"] - df[\"BOppTOV\"]))\n",
    "        + (0.2 * (df[\"ADRPct\"] - df[\"BDRPct\"]))\n",
    "        - (0.15 * (df[\"AOppFTR\"] - df[\"BOppFTR\"]))\n",
    "    )\n",
    "\n",
    "    df[\"4F\"] = df[\"4fODiff\"] - df[\"4fDDiff\"]\n",
    "    df.drop([\"4fODiff\", \"4fDDiff\"], axis=1, inplace=True)\n",
    "\n",
    "    df[\"AWin\"] = all_box[\"AWin\"]\n",
    "    df[\"Set\"] = all_box[\"Set\"]\n",
    "\n",
    "    # Merge the seeds dataframe with the main features dataframe\n",
    "    df = (\n",
    "        pd.merge(\n",
    "            df,\n",
    "            men_women_seeds,\n",
    "            how=\"left\",\n",
    "            left_on=[\"Season\", \"TeamA\"],\n",
    "            right_on=[\"Season\", \"TeamID\"],\n",
    "        )\n",
    "        .drop(\"TeamID\", axis=1)\n",
    "        .rename(columns={\"Seed\": \"SeedA\"})\n",
    "    )\n",
    "    df = (\n",
    "        pd.merge(\n",
    "            df,\n",
    "            men_women_seeds,\n",
    "            how=\"left\",\n",
    "            left_on=[\"Season\", \"TeamB\"],\n",
    "            right_on=[\"Season\", \"TeamID\"],\n",
    "        )\n",
    "        .drop(\"TeamID\", axis=1)\n",
    "        .rename(columns={\"Seed\": \"SeedB\"})\n",
    "    )\n",
    "    df.loc[:, [\"SeedA\", \"SeedB\"]] = df[[\"SeedA\", \"SeedB\"]].fillna(0)\n",
    "\n",
    "    # Create training and test dataset from the dataframe\n",
    "    train = df\n",
    "    train_x_col = train[\n",
    "        [\n",
    "            \"Season\",\n",
    "            \"Set\",\n",
    "            \"Gender\",\n",
    "            \"TeamA\",\n",
    "            \"TeamB\",\n",
    "            \"AWRatio\",\n",
    "            \"BWRatio\",\n",
    "            \"AEFG\",\n",
    "            \"BEFG\",\n",
    "            \"AOppEFG\",\n",
    "            \"BOppEFG\",\n",
    "            \"APPP\",\n",
    "            \"BPPP\",\n",
    "            \"AOppPPP\",\n",
    "            \"BOppPPP\",\n",
    "            \"ATS\",\n",
    "            \"BTS\",\n",
    "            \"AOppTS\",\n",
    "            \"BOppTS\",\n",
    "            \"AORTG\",\n",
    "            \"BORTG\",\n",
    "            \"ADRTG\",\n",
    "            \"BDRTG\",\n",
    "            \"ATOVPct\",\n",
    "            \"BTOVPct\",\n",
    "            \"AOppTOV\",\n",
    "            \"BOppTOV\",\n",
    "            \"AORPct\",\n",
    "            \"BORPct\",\n",
    "            \"ADRPct\",\n",
    "            \"BDRPct\",\n",
    "            \"AFTR\",\n",
    "            \"BFTR\",\n",
    "            \"AOppFTR\",\n",
    "            \"BOppFTR\",\n",
    "            \"4F\",\n",
    "            \"SeedA\",\n",
    "            \"SeedB\",\n",
    "        ]\n",
    "    ]\n",
    "    train_y_col = train[\"AWin\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        train_x_col, train_y_col, test_size=0.3, random_state=0\n",
    "    )\n",
    "\n",
    "    # Scale the data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = pd.DataFrame(\n",
    "        scaler.transform(X_train), columns=X_train.columns, index=X_train.index\n",
    "    )\n",
    "    X_test = pd.DataFrame(\n",
    "        scaler.transform(X_test), columns=X_test.columns, index=X_test.index\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler, df, men_women_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e02e00-b513-4324-9601-1563d80323d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:26.572492Z",
     "iopub.status.busy": "2025-03-04T00:40:26.572128Z",
     "iopub.status.idle": "2025-03-04T00:40:29.890794Z",
     "shell.execute_reply": "2025-03-04T00:40:29.889688Z",
     "shell.execute_reply.started": "2025-03-04T00:40:26.572458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    scaler,\n",
    "    df,\n",
    "    men_women_seeds,\n",
    ") = create_train_and_test_data(\n",
    "    men_tournament, men_seeds, men_regular, women_tournament, women_seeds, women_regular\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba022f3-d1fe-44fb-81f8-39b635277ef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:29.892196Z",
     "iopub.status.busy": "2025-03-04T00:40:29.891834Z",
     "iopub.status.idle": "2025-03-04T00:40:38.627855Z",
     "shell.execute_reply": "2025-03-04T00:40:38.626760Z",
     "shell.execute_reply.started": "2025-03-04T00:40:29.892167Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Some plotting to visualize a feature from the data and how that feature has changed over the seasons... can specify the feature and the gender\n",
    "\n",
    "column_name = \"AEFG\"\n",
    "n_seasons = len(df[df[\"Gender\"] == 1][\"Season\"].unique())\n",
    "n_rows = (n_seasons + 4) // 5\n",
    "palette = sns.color_palette(\"husl\", n_seasons)\n",
    "season_color = {\n",
    "    val: palette[i] for i, val in enumerate(df[df[\"Gender\"] == 1][\"Season\"].unique())\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=5, figsize=(18, 3 * n_rows))\n",
    "\n",
    "for i, (season, data) in enumerate(df[df[\"Gender\"] == 1].groupby(\"Season\")):\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    sns.kdeplot(\n",
    "        data=data,\n",
    "        x=column_name,\n",
    "        fill=True,\n",
    "        alpha=0.3,\n",
    "        linewidth=2,\n",
    "        color=season_color[season],\n",
    "        ax=axes[row, col],\n",
    "    )\n",
    "    axes[row, col].axvline(data[column_name].median(), color=\"red\", linewidth=2)\n",
    "    axes[row, col].set_title(f\"Season {season}\")\n",
    "\n",
    "    # add scatter plot of median\n",
    "    ax_median = plt.subplot(n_rows, 5, n_seasons + 1)\n",
    "    ax_median.scatter(\n",
    "        season, data[column_name].median(), color=season_color[season], s=100\n",
    "    )\n",
    "    ax_median.set_xlabel(\"Season\")\n",
    "    ax_median.set_ylabel(\"Median\")\n",
    "    ax_median.set_xticks(df[df[\"Gender\"] == 1][\"Season\"].unique())\n",
    "    ax_median.set_xticklabels(df[df[\"Gender\"] == 1][\"Season\"].unique(), rotation=45)\n",
    "    ax_median.set_title(\"Median by Season (Gender 1)\")\n",
    "\n",
    "    # add trendline to median scatter plot\n",
    "    x = np.array(df[df[\"Gender\"] == 1][\"Season\"].unique())\n",
    "    y = np.array(\n",
    "        [\n",
    "            data[column_name].median()\n",
    "            for season, data in df[df[\"Gender\"] == 1].groupby(\"Season\")\n",
    "        ]\n",
    "    )\n",
    "    p = np.polyfit(x, y, deg=2)\n",
    "    f = np.poly1d(p)\n",
    "    x_new = np.linspace(x[0], x[-1], 100)\n",
    "    ax_median.plot(x_new, f(x_new), color=\"black\", linewidth=2)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72da7520-ee87-416f-97c7-f707ba9b4fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:38.629131Z",
     "iopub.status.busy": "2025-03-04T00:40:38.628862Z",
     "iopub.status.idle": "2025-03-04T00:40:38.633169Z",
     "shell.execute_reply": "2025-03-04T00:40:38.632058Z",
     "shell.execute_reply.started": "2025-03-04T00:40:38.629099Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed909431-8b18-4ffd-ad61-a14ce0ca690f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:38.634613Z",
     "iopub.status.busy": "2025-03-04T00:40:38.634195Z",
     "iopub.status.idle": "2025-03-04T00:40:38.655573Z",
     "shell.execute_reply": "2025-03-04T00:40:38.654468Z",
     "shell.execute_reply.started": "2025-03-04T00:40:38.634579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "scores = {\"XGB\": {}}\n",
    "importances = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe81275b-f9c5-481e-8395-b73759d6f49f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:40:38.660269Z",
     "iopub.status.busy": "2025-03-04T00:40:38.659937Z",
     "iopub.status.idle": "2025-03-04T00:41:15.889576Z",
     "shell.execute_reply": "2025-03-04T00:41:15.888799Z",
     "shell.execute_reply.started": "2025-03-04T00:40:38.660240Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# XGBoost performed best and was then used for training\n",
    "\n",
    "xgb_clf = xgboost.XGBClassifier()\n",
    "brier = cross_val_score(\n",
    "    xgb_clf, X_train, y_train, cv=k_fold, n_jobs=1, scoring=\"neg_brier_score\"\n",
    ")\n",
    "brier = np.mean(brier) * -1\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "pred_Y = xgb_clf.predict_proba(X_test)\n",
    "scores[\"XGB\"][\"Brier\"] = brier\n",
    "importances[\"XGB\"] = xgb_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d885e32c-d91d-447d-9722-7d883cd7cbf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:41:15.890998Z",
     "iopub.status.busy": "2025-03-04T00:41:15.890737Z",
     "iopub.status.idle": "2025-03-04T00:41:15.899735Z",
     "shell.execute_reply": "2025-03-04T00:41:15.898881Z",
     "shell.execute_reply.started": "2025-03-04T00:41:15.890974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create dataframes for both the score dictionary and importance dictionary\n",
    "\n",
    "score_df = pd.DataFrame.from_dict(scores).T\n",
    "importances_df = pd.DataFrame.from_dict(importances)\n",
    "importances_df.index = X_train.columns\n",
    "importances_df[\"mean_importance\"] = importances_df.mean(axis=1)\n",
    "importances_df = importances_df.sort_values(by=\"XGB\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff82cff1-d7aa-47f2-9696-8e87e6dfd5c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:41:15.901437Z",
     "iopub.status.busy": "2025-03-04T00:41:15.900464Z",
     "iopub.status.idle": "2025-03-04T00:41:15.925136Z",
     "shell.execute_reply": "2025-03-04T00:41:15.924305Z",
     "shell.execute_reply.started": "2025-03-04T00:41:15.901377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad79c59-500a-403c-8f69-df0d774d63b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:41:15.926660Z",
     "iopub.status.busy": "2025-03-04T00:41:15.926278Z",
     "iopub.status.idle": "2025-03-04T00:41:15.949254Z",
     "shell.execute_reply": "2025-03-04T00:41:15.948454Z",
     "shell.execute_reply.started": "2025-03-04T00:41:15.926625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d45af8-8e7f-4bb9-a71c-1c7fc179f53e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:41:15.950383Z",
     "iopub.status.busy": "2025-03-04T00:41:15.950099Z",
     "iopub.status.idle": "2025-03-04T00:41:15.969926Z",
     "shell.execute_reply": "2025-03-04T00:41:15.969106Z",
     "shell.execute_reply.started": "2025-03-04T00:41:15.950359Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_input_data(year, scaler, men_women_seeds):\n",
    "    # Load in sample submission and format\n",
    "    sample = pd.read_csv(\n",
    "        \"/kaggle/input/march-machine-learning-mania-2025/SampleSubmissionStage2.csv\"\n",
    "    )\n",
    "    sample[\"ID\"] = sample[\"ID\"].str.replace(\"2025_\", str(year) + \"_\", regex=False)\n",
    "    sample[\"Season\"] = sample[\"ID\"].apply(lambda x: int(x.split(\"_\")[0]))\n",
    "    sample[\"TeamA\"] = sample[\"ID\"].apply(lambda x: int(x.split(\"_\")[1]))\n",
    "    sample[\"TeamB\"] = sample[\"ID\"].apply(lambda x: int(x.split(\"_\")[2]))\n",
    "\n",
    "    sample[\"Season\"] = sample.Season.astype(\"int\")\n",
    "    sample[\"TeamA\"] = sample.TeamA.astype(\"int\")\n",
    "    sample[\"TeamB\"] = sample.TeamB.astype(\"int\")\n",
    "\n",
    "    # Merge sample with seed data\n",
    "    sample = (\n",
    "        sample.merge(\n",
    "            men_women_seeds[[\"Season\", \"Seed\", \"TeamID\"]],\n",
    "            how=\"left\",\n",
    "            left_on=[\"Season\", \"TeamA\"],\n",
    "            right_on=[\"Season\", \"TeamID\"],\n",
    "        )\n",
    "        .drop(\"TeamID\", axis=1)\n",
    "        .rename(columns={\"Seed\": \"SeedA\"})\n",
    "        .fillna(0)\n",
    "    )\n",
    "    sample = (\n",
    "        sample.merge(\n",
    "            men_women_seeds[[\"Season\", \"Seed\", \"TeamID\"]],\n",
    "            how=\"left\",\n",
    "            left_on=[\"Season\", \"TeamB\"],\n",
    "            right_on=[\"Season\", \"TeamID\"],\n",
    "        )\n",
    "        .drop(\"TeamID\", axis=1)\n",
    "        .rename(columns={\"Seed\": \"SeedB\"})\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    # Merge submission_df with the engineered features\n",
    "    # The data for 2025 is only the regular season... denote this with \"0\"\n",
    "    sample = pd.merge(\n",
    "        sample,\n",
    "        df[\n",
    "            [\n",
    "                \"Season\",\n",
    "                \"TeamA\",\n",
    "                \"Gender\",\n",
    "                \"AWRatio\",\n",
    "                \"AEFG\",\n",
    "                \"AOppEFG\",\n",
    "                \"APPP\",\n",
    "                \"AOppPPP\",\n",
    "                \"ATS\",\n",
    "                \"AOppTS\",\n",
    "                \"AORTG\",\n",
    "                \"ADRTG\",\n",
    "                \"ATOVPct\",\n",
    "                \"AOppTOV\",\n",
    "                \"AORPct\",\n",
    "                \"ADRPct\",\n",
    "                \"AFTR\",\n",
    "                \"AOppFTR\",\n",
    "            ]\n",
    "        ]\n",
    "        .groupby([\"Season\", \"TeamA\"])\n",
    "        .mean(),\n",
    "        on=[\"Season\", \"TeamA\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    sample = pd.merge(\n",
    "        sample,\n",
    "        df[\n",
    "            [\n",
    "                \"Season\",\n",
    "                \"TeamB\",\n",
    "                \"BWRatio\",\n",
    "                \"BEFG\",\n",
    "                \"BOppEFG\",\n",
    "                \"BPPP\",\n",
    "                \"BOppPPP\",\n",
    "                \"BTS\",\n",
    "                \"BOppTS\",\n",
    "                \"BORTG\",\n",
    "                \"BDRTG\",\n",
    "                \"BTOVPct\",\n",
    "                \"BOppTOV\",\n",
    "                \"BORPct\",\n",
    "                \"BDRPct\",\n",
    "                \"BFTR\",\n",
    "                \"BOppFTR\",\n",
    "            ]\n",
    "        ]\n",
    "        .groupby([\"Season\", \"TeamB\"])\n",
    "        .mean(),\n",
    "        on=[\"Season\", \"TeamB\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    sample[\"Set\"] = 0\n",
    "    sample[\n",
    "        [\n",
    "            \"Gender\",\n",
    "            \"AWRatio\",\n",
    "            \"AEFG\",\n",
    "            \"AOppEFG\",\n",
    "            \"APPP\",\n",
    "            \"AOppPPP\",\n",
    "            \"ATS\",\n",
    "            \"AOppTS\",\n",
    "            \"AORTG\",\n",
    "            \"ADRTG\",\n",
    "            \"ATOVPct\",\n",
    "            \"AOppTOV\",\n",
    "            \"AORPct\",\n",
    "            \"ADRPct\",\n",
    "            \"AFTR\",\n",
    "            \"AOppFTR\",\n",
    "            \"TeamB\",\n",
    "            \"BWRatio\",\n",
    "            \"BEFG\",\n",
    "            \"BOppEFG\",\n",
    "            \"BPPP\",\n",
    "            \"BOppPPP\",\n",
    "            \"BTS\",\n",
    "            \"BOppTS\",\n",
    "            \"BORTG\",\n",
    "            \"BDRTG\",\n",
    "            \"BTOVPct\",\n",
    "            \"BOppTOV\",\n",
    "            \"BORPct\",\n",
    "            \"BDRPct\",\n",
    "            \"BFTR\",\n",
    "            \"BOppFTR\",\n",
    "        ]\n",
    "    ] = sample[\n",
    "        [\n",
    "            \"Gender\",\n",
    "            \"AWRatio\",\n",
    "            \"AEFG\",\n",
    "            \"AOppEFG\",\n",
    "            \"APPP\",\n",
    "            \"AOppPPP\",\n",
    "            \"ATS\",\n",
    "            \"AOppTS\",\n",
    "            \"AORTG\",\n",
    "            \"ADRTG\",\n",
    "            \"ATOVPct\",\n",
    "            \"AOppTOV\",\n",
    "            \"AORPct\",\n",
    "            \"ADRPct\",\n",
    "            \"AFTR\",\n",
    "            \"AOppFTR\",\n",
    "            \"TeamB\",\n",
    "            \"BWRatio\",\n",
    "            \"BEFG\",\n",
    "            \"BOppEFG\",\n",
    "            \"BPPP\",\n",
    "            \"BOppPPP\",\n",
    "            \"BTS\",\n",
    "            \"BOppTS\",\n",
    "            \"BORTG\",\n",
    "            \"BDRTG\",\n",
    "            \"BTOVPct\",\n",
    "            \"BOppTOV\",\n",
    "            \"BORPct\",\n",
    "            \"BDRPct\",\n",
    "            \"BFTR\",\n",
    "            \"BOppFTR\",\n",
    "        ]\n",
    "    ].fillna(\n",
    "        sample[\n",
    "            [\n",
    "                \"Gender\",\n",
    "                \"AWRatio\",\n",
    "                \"AEFG\",\n",
    "                \"AOppEFG\",\n",
    "                \"APPP\",\n",
    "                \"AOppPPP\",\n",
    "                \"ATS\",\n",
    "                \"AOppTS\",\n",
    "                \"AORTG\",\n",
    "                \"ADRTG\",\n",
    "                \"ATOVPct\",\n",
    "                \"AOppTOV\",\n",
    "                \"AORPct\",\n",
    "                \"ADRPct\",\n",
    "                \"AFTR\",\n",
    "                \"AOppFTR\",\n",
    "                \"TeamB\",\n",
    "                \"BWRatio\",\n",
    "                \"BEFG\",\n",
    "                \"BOppEFG\",\n",
    "                \"BPPP\",\n",
    "                \"BOppPPP\",\n",
    "                \"BTS\",\n",
    "                \"BOppTS\",\n",
    "                \"BORTG\",\n",
    "                \"BDRTG\",\n",
    "                \"BTOVPct\",\n",
    "                \"BOppTOV\",\n",
    "                \"BORPct\",\n",
    "                \"BDRPct\",\n",
    "                \"BFTR\",\n",
    "                \"BOppFTR\",\n",
    "            ]\n",
    "        ].mean()\n",
    "    )\n",
    "\n",
    "    # Engineer the last feature and select the features for predictions\n",
    "    sample[[\"Season\", \"TeamB\", \"TeamA\", \"SeedA\", \"SeedB\", \"Gender\", \"Set\"]] = sample[\n",
    "        [\"Season\", \"TeamB\", \"TeamA\", \"SeedA\", \"SeedB\", \"Gender\", \"Set\"]\n",
    "    ].astype(int)\n",
    "    sample[\"4fODiff\"] = (\n",
    "        (0.4 * (sample[\"AEFG\"] - sample[\"BEFG\"]))\n",
    "        - (0.25 * (sample[\"ATOVPct\"] - sample[\"BTOVPct\"]))\n",
    "        + (0.2 * (sample[\"AORPct\"] - sample[\"BORPct\"]))\n",
    "        + (0.15 * (sample[\"AFTR\"] - sample[\"BFTR\"]))\n",
    "    )\n",
    "    sample[\"4fDDiff\"] = (\n",
    "        -(0.4 * (sample[\"AOppEFG\"] - sample[\"BOppEFG\"]))\n",
    "        + (0.25 * (sample[\"AOppTOV\"] - sample[\"BOppTOV\"]))\n",
    "        + (0.2 * (sample[\"ADRPct\"] - sample[\"BDRPct\"]))\n",
    "        - (0.15 * (sample[\"AOppFTR\"] - sample[\"BOppFTR\"]))\n",
    "    )\n",
    "    sample[\"4F\"] = sample[\"4fODiff\"] - sample[\"4fDDiff\"]\n",
    "    sample.drop([\"4fODiff\", \"4fDDiff\"], axis=1, inplace=True)\n",
    "    sample = sample[\n",
    "        [\n",
    "            \"Season\",\n",
    "            \"Set\",\n",
    "            \"Gender\",\n",
    "            \"TeamA\",\n",
    "            \"TeamB\",\n",
    "            \"AWRatio\",\n",
    "            \"BWRatio\",\n",
    "            \"AEFG\",\n",
    "            \"BEFG\",\n",
    "            \"AOppEFG\",\n",
    "            \"BOppEFG\",\n",
    "            \"APPP\",\n",
    "            \"BPPP\",\n",
    "            \"AOppPPP\",\n",
    "            \"BOppPPP\",\n",
    "            \"ATS\",\n",
    "            \"BTS\",\n",
    "            \"AOppTS\",\n",
    "            \"BOppTS\",\n",
    "            \"AORTG\",\n",
    "            \"BORTG\",\n",
    "            \"ADRTG\",\n",
    "            \"BDRTG\",\n",
    "            \"ATOVPct\",\n",
    "            \"BTOVPct\",\n",
    "            \"AOppTOV\",\n",
    "            \"BOppTOV\",\n",
    "            \"AORPct\",\n",
    "            \"BORPct\",\n",
    "            \"ADRPct\",\n",
    "            \"BDRPct\",\n",
    "            \"AFTR\",\n",
    "            \"BFTR\",\n",
    "            \"AOppFTR\",\n",
    "            \"BOppFTR\",\n",
    "            \"4F\",\n",
    "            \"SeedA\",\n",
    "            \"SeedB\",\n",
    "        ]\n",
    "    ]\n",
    "    # Scale data\n",
    "    sample = pd.DataFrame(\n",
    "        scaler.transform(sample), columns=sample.columns, index=sample.index\n",
    "    )\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4520127e-7b4b-4a12-b912-914866e837a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:41:15.971224Z",
     "iopub.status.busy": "2025-03-04T00:41:15.970955Z",
     "iopub.status.idle": "2025-03-04T00:41:16.847081Z",
     "shell.execute_reply": "2025-03-04T00:41:16.846218Z",
     "shell.execute_reply.started": "2025-03-04T00:41:15.971201Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample = create_input_data(2025, scaler, men_women_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e394cb-a7c0-4c91-94b3-42906a449d51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:41:16.848469Z",
     "iopub.status.busy": "2025-03-04T00:41:16.848107Z",
     "iopub.status.idle": "2025-03-04T00:41:16.872341Z",
     "shell.execute_reply": "2025-03-04T00:41:16.871363Z",
     "shell.execute_reply.started": "2025-03-04T00:41:16.848432Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa1aa32-e759-4b2e-8fc7-eb8dd35367d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:41:16.873710Z",
     "iopub.status.busy": "2025-03-04T00:41:16.873307Z",
     "iopub.status.idle": "2025-03-04T00:41:17.119816Z",
     "shell.execute_reply": "2025-03-04T00:41:17.119029Z",
     "shell.execute_reply.started": "2025-03-04T00:41:16.873632Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Predict on submission set and prepare submission for the competition\n",
    "\n",
    "submission_df = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/SampleSubmissionStage2.csv\"\n",
    ")\n",
    "sub_pred = xgb_clf.predict_proba(sample).astype(float)\n",
    "sub_pred = sub_pred[:, 1]\n",
    "submission_df[\"Pred\"] = sub_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2d586-b15b-4e6d-90cb-4e4ab025d1ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:41:17.120671Z",
     "iopub.status.busy": "2025-03-04T00:41:17.120424Z",
     "iopub.status.idle": "2025-03-04T00:41:17.129670Z",
     "shell.execute_reply": "2025-03-04T00:41:17.128907Z",
     "shell.execute_reply.started": "2025-03-04T00:41:17.120649Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67fe9af",
   "metadata": {},
   "source": [
    "# Create label data and evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f699d5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:41:17.131438Z",
     "iopub.status.busy": "2025-03-04T00:41:17.130851Z",
     "iopub.status.idle": "2025-03-04T00:41:17.169992Z",
     "shell.execute_reply": "2025-03-04T00:41:17.169108Z",
     "shell.execute_reply.started": "2025-03-04T00:41:17.131409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Use tourney results for evaluation\n",
    "m_tourney = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/MNCAATourneyCompactResults.csv\"\n",
    ")\n",
    "w_tourney = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/WNCAATourneyCompactResults.csv\"\n",
    ")\n",
    "tourney_results = pd.concat([m_tourney, w_tourney])\n",
    "print(tourney_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d470bab4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:41:17.171140Z",
     "iopub.status.busy": "2025-03-04T00:41:17.170890Z",
     "iopub.status.idle": "2025-03-04T00:41:17.176740Z",
     "shell.execute_reply": "2025-03-04T00:41:17.175796Z",
     "shell.execute_reply.started": "2025-03-04T00:41:17.171119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_all_tourney_combination(tourney_results):\n",
    "    # Ensure small ID comes first\n",
    "    df = tourney_results.copy()\n",
    "    df[\"SmallID\"] = df[[\"WTeamID\", \"LTeamID\"]].min(axis=1)\n",
    "    df[\"BigID\"] = df[[\"WTeamID\", \"LTeamID\"]].max(axis=1)\n",
    "\n",
    "    # Create ID in the format year_smallerId_biggerId\n",
    "    df[\"ID\"] = (\n",
    "        df[\"Season\"].astype(str)\n",
    "        + \"_\"\n",
    "        + df[\"SmallID\"].astype(str)\n",
    "        + \"_\"\n",
    "        + df[\"BigID\"].astype(str)\n",
    "    )\n",
    "\n",
    "    # Set prediction based on the original winner\n",
    "    df[\"Pred\"] = (df[\"SmallID\"] == df[\"WTeamID\"]).astype(int)\n",
    "\n",
    "    return df[[\"ID\", \"Pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ad662",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:41:17.178166Z",
     "iopub.status.busy": "2025-03-04T00:41:17.177790Z",
     "iopub.status.idle": "2025-03-04T00:41:17.209777Z",
     "shell.execute_reply": "2025-03-04T00:41:17.208463Z",
     "shell.execute_reply.started": "2025-03-04T00:41:17.178131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tourney_df = create_all_tourney_combination(tourney_results)\n",
    "print(tourney_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b065fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:41:17.211505Z",
     "iopub.status.busy": "2025-03-04T00:41:17.211077Z",
     "iopub.status.idle": "2025-03-04T00:41:17.216730Z",
     "shell.execute_reply": "2025-03-04T00:41:17.215721Z",
     "shell.execute_reply.started": "2025-03-04T00:41:17.211465Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "\n",
    "def create_evaluation_data(tourney_df, prediction):\n",
    "    # Merge to keep only matching IDs\n",
    "    merged_df = tourney_df.merge(prediction, on=\"ID\", suffixes=(\"_true\", \"_pred\"))\n",
    "    if merged_df.empty:\n",
    "        # If there are no matchings between label data and prediction, return 0\n",
    "        return None\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64a42ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:41:17.218185Z",
     "iopub.status.busy": "2025-03-04T00:41:17.217854Z",
     "iopub.status.idle": "2025-03-04T00:41:57.643101Z",
     "shell.execute_reply": "2025-03-04T00:41:57.642080Z",
     "shell.execute_reply.started": "2025-03-04T00:41:17.218160Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate average brier score\n",
    "brier_score_sum = 0\n",
    "count = 0\n",
    "# Read Data\n",
    "men_tournament = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/MNCAATourneyDetailedResults.csv\"\n",
    ")\n",
    "men_seeds = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/MNCAATourneySeeds.csv\"\n",
    ")\n",
    "men_regular = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/MRegularSeasonDetailedResults.csv\"\n",
    ")\n",
    "women_tournament = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/WNCAATourneyDetailedResults.csv\"\n",
    ")\n",
    "women_seeds = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/WNCAATourneySeeds.csv\"\n",
    ")\n",
    "women_regular = pd.read_csv(\n",
    "    \"/kaggle/input/march-machine-learning-mania-2025/WRegularSeasonDetailedResults.csv\"\n",
    ")\n",
    "\n",
    "for year in range(2019, 2025):\n",
    "    # Extract data accoding to year\n",
    "    men_tournament_extracted = men_tournament[men_tournament[\"Season\"] < year]\n",
    "    men_seeds_extracted = men_seeds[men_seeds[\"Season\"] <= year]\n",
    "    men_regular_extracted = men_regular[men_regular[\"Season\"] <= year]\n",
    "    women_tournament_extracted = women_tournament[women_tournament[\"Season\"] < year]\n",
    "    women_seeds_extracted = women_seeds[women_seeds[\"Season\"] <= year]\n",
    "    women_regular_extracted = women_regular[women_regular[\"Season\"] <= year]\n",
    "\n",
    "    (\n",
    "        X_train,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        scaler,\n",
    "        df,\n",
    "        men_women_seeds,\n",
    "    ) = create_train_and_test_data(\n",
    "        men_tournament_extracted,\n",
    "        men_seeds_extracted,\n",
    "        men_regular_extracted,\n",
    "        women_tournament_extracted,\n",
    "        women_seeds_extracted,\n",
    "        women_regular_extracted,\n",
    "    )\n",
    "    xgb_clf = xgboost.XGBClassifier()\n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "    pred_df = pd.read_csv(\n",
    "        \"/kaggle/input/march-machine-learning-mania-2025/SampleSubmissionStage2.csv\"\n",
    "    )\n",
    "    pred_df[\"ID\"] = pred_df[\"ID\"].str.replace(\"2025_\", str(year) + \"_\", regex=False)\n",
    "\n",
    "    # Predict result\n",
    "    test_data = create_input_data(year, scaler, men_women_seeds)\n",
    "    prediction_test_data = xgb_clf.predict_proba(test_data).astype(float)\n",
    "    prediction_test_data = prediction_test_data[:, 1]\n",
    "    pred_df[\"Pred\"] = prediction_test_data\n",
    "\n",
    "    # Extract matching values\n",
    "    merged_df = create_evaluation_data(tourney_df, pred_df)\n",
    "\n",
    "    # Calculate brier score\n",
    "    if not merged_df is None:\n",
    "        y_true = merged_df[\"Pred_true\"]  # Actual results (0 or 1)\n",
    "        y_pred = merged_df[\"Pred_pred\"]  # Predicted probabilities\n",
    "        year_brier_score = brier_score_loss(y_true, y_pred)\n",
    "        brier_score_sum += year_brier_score\n",
    "        print(\"{0}: {1}\".format(year, year_brier_score))\n",
    "        count += 1\n",
    "\n",
    "print(\"count: \", count)\n",
    "brier_score = brier_score_sum / count\n",
    "print(\"Average brier score:\", brier_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eca88f9",
   "metadata": {
    "papermill": {
     "duration": 0.005092,
     "end_time": "2025-02-24T23:07:33.781273",
     "exception": false,
     "start_time": "2025-02-24T23:07:33.776181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464c1d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T00:41:57.644477Z",
     "iopub.status.busy": "2025-03-04T00:41:57.644106Z",
     "iopub.status.idle": "2025-03-04T00:41:57.927784Z",
     "shell.execute_reply": "2025-03-04T00:41:57.926899Z",
     "shell.execute_reply.started": "2025-03-04T00:41:57.644438Z"
    },
    "papermill": {
     "duration": 0.278355,
     "end_time": "2025-02-24T23:07:34.064797",
     "exception": false,
     "start_time": "2025-02-24T23:07:33.786442",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"/kaggle/working/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11165145,
     "sourceId": 91497,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1059.702184,
   "end_time": "2025-02-24T23:07:34.892198",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-24T22:49:55.190014",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
